---
version: "3"

tasks:
  flux:verify:
    desc: Verify flux meets the prerequisites
    cmds:
      - flux check --pre

  flux:namespace:
    desc: Create the flux-system namespace
    cmds:
      - kubectl create namespace flux-system --dry-run=client -o yaml | kubectl apply -f -

  flux:secret:
    desc: Create the Age secret in the flux-system namespace
    cmds:
      - cat {{.SOPS_AGE_KEY_FILE}} | kubectl -n flux-system create secret generic sops-age --from-file=age.agekey=/dev/stdin
    preconditions:
      - sh: test -f {{.SOPS_AGE_KEY_FILE}}
        msg: |
          Age key file is not found. Did you forget to create it?
    vars:
      SOPS_AGE_KEY_FILE: ~/.config/sops/age/keys.txt

  flux:install:
    desc: Install Flux into your cluster, run this again if it fails
    cmds:
      - kubectl apply -k {{.CLUSTER_DIR}}/base/flux-system

  list-dockerhub:
    desc: What dockerhub images are running in my cluster
    cmds:
      - kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{'\n'}{range .spec.containers[*]}{.image}{'\n'}{end}{end}" | sort | uniq | grep -Ev 'quay|gcr|ghcr|ecr|us-docker' | grep -Ev 'bitnami|rook|intel|grafana' |  sed -e 's/docker\.io\///g' | sort | uniq

  reconcile:
    desc: Force update Flux to pull in changes from your Git repository
    cmds:
      - flux reconcile source git flux-system {{.CLI_ARGS | default "-n flux-system"}}

  nodes:
    desc: List all the nodes in your cluster
    cmds:
      - kubectl get nodes {{.CLI_ARGS | default "-o wide"}}

  pods:
    desc: List all the pods in your cluster
    cmds:
      - kubectl get pods {{.CLI_ARGS | default "-A"}}

  delete-failed-pods:
    desc: Deletes failed pods
    cmds:
      - kubectl delete pods --field-selector status.phase=Failed -A --ignore-not-found=true

  kustomizations:
    desc: List all the kustomizations in your cluster
    cmds:
      - kubectl get kustomizations {{.CLI_ARGS | default "-A"}}

  helmreleases:
    desc: List all the helmreleases in your cluster
    cmds:
      - kubectl get helmreleases {{.CLI_ARGS | default "-A"}}

  helmrepositories:
    desc: List all the helmreleases in your cluster
    cmds:
      - kubectl get helmrepositories {{.CLI_ARGS | default "-A"}}

  gitrepositories:
    desc: List all the helmreleases in your cluster
    cmds:
      - kubectl get gitrepositories {{.CLI_ARGS | default "-A"}}

  certificates:
    desc: List all the certificates in your cluster
    cmds:
      - kubectl get certificates {{.CLI_ARGS | default "-A"}}
      - kubectl get certificaterequests {{.CLI_ARGS | default "-A"}}

  resources:
    desc: Gather common resources in your cluster, useful when asking for support
    cmds:
      - task: nodes
      - task: kustomizations
      - task: helmreleases
      - task: helmrepositories
      - task: gitrepositories
      - task: certificates
      - task: pods


  volume:
    desc: |-
      Create a container for debugging a PVC (ex. task PVC=plex-config-v1 debug:volume)
    interactive: true
    cmds:
      - |
        kubectl run -n $(kubectl get pvc -A | grep {{.PVC}} | awk '{print $1}') debug-{{.PVC}} -i --tty --rm --image=null --privileged --overrides='
          {
            "apiVersion": "v1",
            "spec": {
              "containers": [
                {
                  "name": "debug",
                  "image": "ghcr.io/onedr0p/alpine:rolling",
                  "command": [
                    "/bin/bash"
                  ],
                  "stdin": true,
                  "stdinOnce": true,
                  "tty": true,
                  "volumeMounts": [
                    {
                      "name": "config",
                      "mountPath": "/data/config"
                    }
                  ]
                }
              ],
              "volumes": [
                {
                  "name": "config",
                  "persistentVolumeClaim": {
                    "claimName": "{{.PVC}}"
                  }
                }
              ],
              "restartPolicy": "Never"
            }
          }'

  debug-node:
    desc: Create a privileged container on a node for debugging, ex. NODE=anvil task debug-node
    interactive: true
    cmds:
      - |
        kubectl run debug-{{.NODE}} -i --tty --rm --image="docker.io/library/alpine:3.15" --privileged --overrides='
          {
            "spec": {
              "nodeSelector": {
                "kubernetes.io/hostname": "{{.NODE}}"
              },
              "restartPolicy": "Never"
            }
          }'

  hr:restart:
    desc: Restart all failed Helm Releases
    cmds:
      - kubectl get hr --all-namespaces | grep False | awk '{print $2, $1}' | xargs -l bash -c 'flux suspend hr $0 -n $1'
      - kubectl get hr --all-namespaces | grep False | awk '{print $2, $1}' | xargs -l bash -c 'flux resume hr $0 -n $1'

  scale-down:
    desc: Scale all deployments/replicas/daemonsets down
    cmds:
      - flux suspend kustomization --all
      - kubectl get deployments -A --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n $1 scale deployment $0 --replicas=0'
      - kubectl get statefulsets -A --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n $1 scale statefulsets $0 --replicas=0'

  kyverno:fix:
    desc: Remove kyverno shit when it breaks everything
    cmds:
      - kubectl delete mutatingwebhookconfigurations kyverno-policy-mutating-webhook-cfg
      - kubectl delete mutatingwebhookconfigurations kyverno-resource-mutating-webhook-cfg
      - kubectl delete mutatingwebhookconfigurations kyverno-verify-mutating-webhook-cfg
      - kubectl delete validatingwebhookconfigurations kyverno-policy-validating-webhook-cfg
      - kubectl delete validatingwebhookconfigurations kyverno-resource-validating-webhook-cfg

  scale-up:
    desc: Scale all deployments/replicas/daemonsets up
    cmds:
      - flux suspend kustomization --all
      - kubectl -n calico-system scale deploy calico-typha --replicas 2
      - kubectl -n calico-system scale deploy calico-kube-controllers --replicas 1
      - kubectl -n calico-apiserver scale deploy calico-apiserver --replicas 2
      - kubectl -n tigera-operator scale deploy tigera-operator --replicas 1
      - kubectl get deployments -n kube-system --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n kube-system scale deployment $1 --replicas=1'
      - kubectl get deployments -n flux-system --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n flux-system scale deployment $1 --replicas=1'
      - kubectl get deployments -n longhorn-system --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n longhorn-system scale deployment $1 --replicas=1'
      - sleep 60
      - kubectl -n databases scale deploy postgres-cloudnative-pg --replicas 1
      - kubectl -n databases scale deploy redis --replicas 1
      - kubectl -n kyverno scale deploy kyverno --replicas 3
      - kubectl -n metallb-system scale deploy metallb-controller --replicas 1
      - kubectl get deployments -n monitoring --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n monitoring scale deployment $1 --replicas=1'
      - sleep 300
      - kubectl -n networking scale deploy ingress-nginx-controller --replicas 1
      - kubectl -n networking scale deploy ingress-nginx-defaultbackend --replicas 1
      - kubectl -n networking scale deploy k8s-gateway --replicas 3
      - kubectl -n databases scale statefulsets emqx --replicas 3
      - kubectl -n kube-system scale statefulsets snapshot-controller --replicas 1
      - kubectl -n monitoring scale statefulsets alertmanager-prometheus-alertmanager --replicas 2
      - kubectl -n monitoring scale statefulsets loki-read --replicas 3
      - kubectl -n monitoring scale statefulsets loki-write --replicas 3
      - kubectl -n monitoring scale statefulsets thanos-storegateway --replicas 1
      - kubectl -n monitoring scale statefulsets prometheus-prometheus-prometheus --replicas 1
      - kubectl -n auth-system scale deploy glauth --replicas 3
      - kubectl -n auth-system scale deploy authelia --replicas 3
      - kubectl -n auth-system scale deploy vaultwarden --replicas 1
      - kubectl -n default scale deploy smtp-relay --replicas 3
      - kubectl get deployments -n home --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n home scale deployment $1 --replicas=1'
      - kubectl -n home scale deploy hajimari --replicas 3
      - kubectl get deployments -n system-upgrade --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n system-upgrade scale deployment $1 --replicas=1'
      - kubectl get deployments -n media --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'kubectl -n media scale deployment $1 --replicas=1'
      - flux resume kustomization --all
