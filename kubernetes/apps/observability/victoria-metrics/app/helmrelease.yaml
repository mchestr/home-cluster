apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: victoria-metrics
spec:
  chart:
    spec:
      chart: victoria-metrics-k8s-stack
      version: 0.38.0
      sourceRef:
        kind: HelmRepository
        name: victoriametrics
        namespace: flux-system
  interval: 15m
  maxHistory: 3
  install:
    crds: CreateReplace
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: stack
    victoria-metrics-operator:
      enabled: true
      env:
        - name: VM_VMALERTDEFAULT_CONFIGRELOADERCPU
          value: 0
        - name: VM_VMAGENTDEFAULT_CONFIGRELOADERCPU
          value: 0
        - name: VM_VMALERTMANAGER_CONFIGRELOADERCPU
          value: 0
      operator:
        disable_prometheus_converter: false # Ensure we keep enabled the converter to sync prom rules to VM rules
        enable_converter_ownership: true # Required to allow VM to remove VM rules it imports if a prometheus rule is deleted

    defaultDashboards:
      enabled: true
      grafanaOperator:
        # -- Create dashboards as CRDs (requires grafana-operator to be installed)
        enabled: false

    defaultRules:
      create: true
      rules:
        groups:
          etcd:
            create: false
          kubernetesSystemControllerManager:
            create: false
          kubernetesSystemScheduler:
            create: false

    vmsingle:
      enabled: true
      spec:
        # -- Data retention period. Possible units character: h(ours), d(ays), w(eeks), y(ears), if no unit character specified - month. The minimum retention period is 24h. See these [docs](https://docs.victoriametrics.com/single-server-victoriametrics/#retention)
        retentionPeriod: "3"
        replicaCount: 1
        extraArgs:
          maxLabelsPerTimeseries: "50"
        storage:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 60Gi
        resources:
          limits:
            memory: 2Gi
          requests:
            cpu: 530m
            memory: 1.2Gi
      ingress:
        enabled: false

    alertmanager:
      enabled: true
      spec:
        externalURL: https://vm.chestr.dev
      ingress:
        enabled: false
      useManagedConfig: true
      config:
        route:
          group_by: ["alertname", "job"]
          group_interval: 10m
          group_wait: 1m
          receiver: pushover
          repeat_interval: 12h
          routes:
            - receiver: "null"
              matchers:
                - alertname=InfoInhibitor
            - receiver: heartbeat
              group_interval: 15s
              group_wait: 0s
              repeat_interval: 5m
              matchers:
                - alertname=Watchdog
            - receiver: pushover
              matchers:
                - severity=~"warning|critical"
        inhibit_rules:
          - source_matchers:
              - severity = "critical"
            target_matchers:
              - severity = "warning"
            equal: ["alertname", "namespace"]
        receivers:
          - name: "null"
          - name: heartbeat
            webhook_configs:
              - url_secret:
                  name: &secret alertmanager-secret
                  key: ALERTMANAGER_HEARTBEAT_URL
          - name: pushover
            pushover_configs:
              - html: true
                message: |-
                  {{- range .Alerts }}
                    {{- if ne .Annotations.description "" }}
                      {{ .Annotations.description }}
                    {{- else if ne .Annotations.summary "" }}
                      {{ .Annotations.summary }}
                    {{- else if ne .Annotations.message "" }}
                      {{ .Annotations.message }}
                    {{- else }}
                      Alert description not available
                    {{- end }}
                    {{- if gt (len .Labels.SortedPairs) 0 }}
                      <small>
                        {{- range .Labels.SortedPairs }}
                          <b>{{ .Name }}:</b> {{ .Value }}
                        {{- end }}
                      </small>
                    {{- end }}
                  {{- end }}
                priority: |-
                  {{ if eq .Status "firing" }}1{{ else }}0{{ end }}
                send_resolved: true
                sound: gamelan
                title: >-
                  [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}]
                  {{ .CommonLabels.alertname }}
                ttl: 86400s
                token:
                  name: *secret
                  key: PUSHOVER_ALERTMANAGER_TOKEN
                user_key:
                  name: *secret
                  key: PUSHOVER_USER_KEY
                url_title: View in Alertmanager

    vmalert:
      enabled: true
      spec:
        extraArgs:
          external.url: https://vm.chestr.dev
      ingress:
        enabled: false

    vmagent:
      enabled: true
      ingress:
        enabled: false
      spec:
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 100Mi

    grafana:
      enabled: false

    prometheus-node-exporter:
      enabled: true

    kube-state-metrics:
      enabled: true

    kubelet:
      enabled: true
      vmScrape:
        spec:
          # drop high cardinality label and useless metrics for cadvisor and kubelet
          metricRelabelConfigs:
            # Drop less useful container CPU metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)"
            # Drop less useful / always zero container memory metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_memory_(failures_total|mapped_file|swap)"
            # Drop less useful container process metrics.
            - sourceLabels: [__name__]
              action: drop
              # regex: 'container_(file_descriptors|tasks_state|threads_max)'
              regex: "container_(tasks_state|threads_max)"
            # Drop less useful container filesystem metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)"
            # Drop less useful container blkio metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_blkio_device_usage_total"
            # Drop container spec metrics that overlap with kube-state-metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_spec.*"
            # Drop cgroup metrics with no pod.
            - sourceLabels: [id, pod]
              action: drop
              regex: ".+;"
            - action: drop
              sourceLabels: [__name__]
              regex: prober_probe_duration_seconds_bucket
            # Drop high-cardinality labels.
            - action: labeldrop
              regex: (uid|id|pod_uid|interface)
            - action: drop
              sourceLabels: [__name__]
              regex: (rest_client_request_duration_seconds_bucket|rest_client_request_duration_seconds_sum|rest_client_request_duration_seconds_count)

    kubeApiServer:
      enabled: true

    kubeControllerManager:
      enabled: false

    coreDns:
      enabled: true

    kubeEtcd:
      enabled: false

    kubeScheduler:
      enabled: false

    kubeProxy:
      enabled: false

    prometheus-operator-crds:
      enabled: true

    additionalVictoriaMetricsMap:
      dockerhub-rules:
        create: true
        groups:
          - name: dockerhub
            rules:
              - alert: DockerhubRateLimitRisk
                annotations:
                  summary: Kubernetes cluster Dockerhub rate limit risk
                expr: count(time() - container_last_seen{image=~"(docker.io).*",container!=""} < 30) > 100
                labels:
                  severity: critical
      oom-rules:
        create: true
        groups:
          - name: oom
            rules:
              - alert: OomKilled
                annotations:
                  summary: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
                expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
                labels:
                  severity: critical
